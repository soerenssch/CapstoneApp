import pickle
from pathlib import Path
import streamlit as st
from streamlit_option_menu import option_menu
from outscraper import ApiClient
import pandas as pd
import os
import openai
import requests
from tqdm import tqdm
import time
import datetime
import base64
import subprocess
subprocess.run(['pip', 'install', 'openpyxl'])
from docx import Document
from docx.shared import Inches
import io
from io import BytesIO
import matplotlib.pyplot as plt


st.set_page_config(
    page_title="Sentiment-Analyse",
    page_icon="ðŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded",    
)

logo_left_container = st.container()
with logo_left_container:
    st.image("VT_logo.png", use_column_width=False, width=150)

st.markdown(
    """
    <style>
    .footer {
        position: fixed;
        bottom: 0;
        right: 0;
        font-size: 12px;
        padding: 5px;
    }
    </style>
    """,
    unsafe_allow_html=True,
)
st.markdown(
    '<div class="footer">Â© 2023 Capstone Gruppe Research. All rights reserved.</div>',
    unsafe_allow_html=True,
)


WebScraping = "Schritt 1: Web Scraping"
SentimentAnalyse = "Schritt 2: Sentiment-Analyse"
Anleitung = "Beschreibung & Kontakt"

st.sidebar.title("WÃ¤hle die Inputmethode")
input_method = st.sidebar.radio("WÃ¤hle eine Option:", (WebScraping, SentimentAnalyse, Anleitung))


# Depending on which option is selected, display the appropriate information
if input_method == WebScraping:
    with st.sidebar:
        st.header("Beschreibung: Web Scraping")
        st.write("Im ersten Schritt werden dir die Reviews der jeweils ausgewÃ¤hlten Standorte per Web Scraping zum Download zur VerfÃ¼gung gestellt.")
        # Add any additional information or instructions for this option

elif input_method == SentimentAnalyse:
    with st.sidebar:
        st.header("Beschreibung: Sentiment-Analyse")
        st.write("In diesem Schritt werden die zuvor gescrapten Reviews hochgeladen und ausgewertet.")

elif input_method == Anleitung:
    with st.sidebar:
        st.write("Hier findest du einen Ãœberblick Ã¼ber die Funktionsweise sowie die einzelnen Schritte der Sentiment-Analyse. ZusÃ¤tzlich liegt ein Kontaktformular vor, solltest du auftretende Fragen haben.")


### WebScraping
ID_MAP = {
    "Flint's Praxis fÃ¼r Kleintiere": "ChIJg9LTCjq2kUcRlNmsxEGdNoc",
    'Tierhotel Clinica Alpina Ramosch': "ChIJn9GuzVU3g0cRZAPoW82_WZ0",
    'Tierklinik Clinica Alpina Celerina': "ChIJi2rFwxh9g0cRKh_m8hTN8SA",
    'Tierklinik Clinica Alpina Scuol': "ChIJhf6QYJBHg0cRIe8DYQz8JV8",
    'Kleintierklinik am Damm, Gossau': "ChIJsXk3JcvgmkcRmMwJslg2xcU",
    'Kleintierpraxis Aabach Uster': "ChIJE9cxb6CkmkcRH3ybj-adIbE",
    'Kleintierpraxis Au': "ChIJm8-ANlQRm0cRnd3hTS279ag",
    'Kleintierpraxis Bachmatt Eschenbach': "ChIJnU4TOnT9j0cR6HQvLSgsS5Q",
    'Kleintierpraxis Basel Central': "ChIJAR4_G0-4kUcRQAgkjVkUSek",
    'Kleintierpraxis Basel Spalen': "ChIJqRyBUAG5kUcRVcVH76IXaFE",
    'Kleintierpraxis BÃ¼lach': "ChIJS9aRbdJ1kEcRhKrcNtRWsuA",
    'Kleintierpraxis FÃ¤llanden': "ChIJzZH-veOjmkcR7GUzmVWaezY",
    'Kleintierpraxis Glattbrugg': "ChIJ9UNysAigmkcR5QgQSw4lpiY",
    'Kleintierpraxis GÃ¼mligen': "ChIJv5D40wE3jkcRFKWuw1rHTtE",
    'Kleintierpraxis im Bahnhof, Aathal': "ChIJ6Z-zRnG7mkcRPBbZp4n8iww",
    'Kleintierpraxis KÃ¼ssnacht am Rigi': "ChIJHY_A-m7_j0cRHUpOOIwa8Yo",
    'Kleintierpraxis MÃ¼hlebach Oftringen': "ChIJf_mbzJQvkEcRicJ5NcgPDuE",
    'Kleintierpraxis MÃ¼nchenstein': "ChIJvwTRBxe4kUcRfEUl0F_UF4Y",
    'Kleintierpraxis Muri': "ChIJ5-00QTwFkEcRG9Hk9XEzIM8",
    'Kleintierpraxis Oensingen': "ChIJg3c2oE7SkUcRy_Yz-zeQUww",
    'Kleintierpraxis Regensdorf': "ChIJF5STJ2cLkEcRDRye_BfHcDc",
    'Kleintierpraxis Schlieren': "ChIJERk9VbMNkEcRPy81sQi1wic",
    'Kleintierpraxis St. Gallen Ost': "ChIJTeRhD_Qem0cRdZHi-gV_KQc",
    'Kleintierpraxis Stansstad': "ChIJO7t-Rkb3j0cRhQ4zkf4JuBs",
    'Kleintierpraxis Telli Aarau': "ChIJaZqDHPw7kEcR-Fp5zfYNNdI",
    'Kleintierpraxis Therwil': "ChIJdUCYp3bHkUcRnqgwh2XgkjI",
    'Kleintierpraxis Trimbach': "ChIJlxwBXNMxkEcRVFq9hfD4rYc",
    'Kleintierpraxis Turbenthal': "ChIJGyWX2Q2WmkcRx1gLsoFhMz8",
    'Kleintierpraxis Wettingen': "ChIJGY-uTiltkEcR5qPVT9EHlVU",
    'Kleintierpraxis Winterthur im Zentrum': "ChIJK9ieJXmZmkcRHtJtVS47ZwE",
    'Kleintierpraxis Zug': "ChIJtSFUYUWqmkcRnQZS-2NJx-w",
    'Kleintierpraxis Zuzwil': "ChIJPWi96nfpmkcRMxRLWqMgC5s",
    'Tierklinik Basel': "ChIJpSNsIru5kUcRx-XRYVJBeU4",
    'Tierklinik Nesslau': "ChIJb_dA_kPXmkcRAGqsVT1wLFE",
    'Tierklinik Oberland PfÃ¤ffikon': "ChIJkTyE5WG8mkcR9FjBoEAKIEE",
    'Tierklinik Oberland Saland': "ChIJ2RDiJW6-mkcRRKSDQ0onkc4",
    'Tierklinik ZÃ¼rich': "ChIJNXoM5QOhmkcRBNaok_HRShE",
    'Zentrum fÃ¼r Tiermedizin Klettgau': "ChIJH2Ls-3Z8kEcRvq0oZ5ctkrk",
}

input_Outscraper = []
checkbox_states = {label: False for label in ID_MAP.keys()}
checkbox_states["Select all"] = False

def update_selection(ID_MAP, checkbox_states, key):
    checkbox_states[key] = not checkbox_states[key]  # toggle the state of the clicked checkbox
    if key == "Select all":
        for label in ID_MAP.keys():
            checkbox_states[label] = checkbox_states[key]
    else:
        if not checkbox_states[key]:
            checkbox_states["Select all"] = False  # if any checkbox is unchecked, uncheck "Select all"
        else:
            checkbox_states["Select all"] = all(checkbox_states.values())  # if all checkboxes are checked, check "Select all"
    return checkbox_states

if input_method == WebScraping:
    st.write("Mithilfe von Web Scraping werden ab einem ausgewÃ¤hlten Zeitpunkt alle Google Reviews der gewÃ¤hlten Standorte zum Download bereitgestellt. Bitte wÃ¤hle die Standorte aus, die dich interessieren.")


    select_all = st.checkbox("Alle Standorte auswÃ¤hlen")

    place_checkboxes = {}
    for place in ID_MAP:
        if select_all:
            place_checkboxes[place] = st.checkbox(place, value=True)
            input_Outscraper.append(ID_MAP[place])
        else:
            place_checkboxes[place] = st.checkbox(place)
        
        if place_checkboxes[place]:
            place_id = ID_MAP[place]
            if place_id not in input_Outscraper:
                input_Outscraper.append(place_id)
        else:
            place_id = ID_MAP[place]
            if place_id in input_Outscraper:
                input_Outscraper.remove(place_id)

    
    date_input = st.date_input('Gib das Datum an, ab dem du die Reviews exportieren willst:')
    if date_input > datetime.datetime.today().date():
        st.error('Fehler: Datum darf nicht in der Zukunft liegen!')
    else:
        year = date_input.year
        month = date_input.month
        day = date_input.day

    my_date = datetime.datetime(year, month, day)
    timestamp = my_date.timestamp()
    timestamp = int(timestamp)
    st.session_state.timestamp = timestamp

    st.write("Melde dich mit dem nachfolgenden Link bei Outscraper an, um deinen eigenen API-Key zu erstellen: https://outscraper.com/refer?referrer=YXV0aDB8NjQwMWIzZGNiZmMzM2FhMmM5ODA4ZWFm")
    
    Outscraper_APIKey = st.text_input("Gib hier deinen Outscraper API-Key an:")
    client = ApiClient(api_key=Outscraper_APIKey)

    

    submit = st.button("Web Scraping durchfÃ¼hren")
    if submit: 
        st.write("Web Scraping wird durchgefÃ¼hrt!")
        @st.cache_data(ttl=600)
        def scrape_google_reviews(query, timestamp):
            results = client.google_maps_reviews([query], sort='newest', cutoff=timestamp, reviews_limit=1000, language='de')
            return results


        results = scrape_google_reviews(input_Outscraper, timestamp)

        data = []
        for place in results:
            name = place['name']
            for review in place.get('reviews_data', []):
                review_text = review['review_text']
                review_rating = review['review_rating']
                date = review["review_datetime_utc"]
                data.append({'Standort': name, 'Review': review_text, 'Rating': review_rating, 'Datum': date})
        df = pd.DataFrame(data)
        st.dataframe(df)

        

        def generate_csv(df):
            return df.to_csv(index=False)

        if st.download_button(label='Download CSV', data=generate_csv(df), file_name='data.csv', mime='text/csv'):
            pass

### SentimentAnalyse  
if input_method == SentimentAnalyse:

    def download_file(file):
        b = BytesIO()
        file.savefig(b, format='png')
        b.seek(0)
        return b

    # Main code
    file = st.file_uploader("Lade deine Datei hier hoch:", type=["csv"])
    if file is not None:
        df = pd.read_csv(file)
        df = df.dropna()

        if "Datum" in df.columns:

            # add checkbox to allow manual date selection
            manual_date_selection = st.checkbox("Den Analysezeitraum manuell festlegen")
            df["Datum"] = pd.to_datetime(df["Datum"])
            if manual_date_selection:

                
                # start_date = st.date_input("Start date")
                # end_date = st.date_input("End date")
                start_date = st.date_input("Start der Auswertung:", value=pd.to_datetime(df['Datum']).min().date())
                end_date = st.date_input("Ende der Auswertung:", value=pd.to_datetime(df['Datum']).max().date())

                # mask = (df["date"] >= start_date) & (df["date"] <= end_date)
                mask = (pd.to_datetime(df['Datum']).dt.date >= start_date) & (pd.to_datetime(df['Datum']).dt.date <= end_date)
                df = df.loc[mask]

        st.dataframe(df)

        if "Rating" in df.columns:
                
            
            def generate_plot(df):
                fig, ax = plt.subplots(figsize=(12, 8))
                counts, bins, patches = ax.hist(df['Rating'], bins=5, color='#132f55', edgecolor='white')
                ax.set_xlabel('Bewertung')
                ax.set_ylabel('Anzahl')
                ax.set_title('Verteilung der Bewertungen')
                tick_labels = ['1 Stern', '2 Sterne', '3 Sterne', '4 Sterne', '5 Sterne']
                tick_positions = [1.415, 2.25, 3, 3.85, 4.63]
                ax.set_xticks(tick_positions)
                ax.set_xticklabels(tick_labels, ha='center') # Set horizontal alignment to center
                return fig
        
            fig = generate_plot(df)
            st.pyplot(fig)
            st.write(f"Die durchschnittliche Bewertung betrÃ¤gt {round(df['Rating'].mean(), 2)} bei {round(df['Rating'].count(), 2)} Bewertungen")
            

            download = download_file(fig)
            st.download_button(
                label='Download plot',
                data=download,
                file_name='plot.png',
                mime='image/png'
            )
            
        Spalte = st.text_input("Wie heisst die Spalte, die du auswerten mÃ¶chtest?")
        if not Spalte:
            Spalte = "Review"

        st.write("Melde dich mit dem nachfolgenden Link bei OpenAI an, um deinen API-Key zu erstellen: https://chat.openai.com/auth/login")
        OpenAI_API = st.text_input("Gib hier deinen OpenAI API-Key an:")
        
        openai.api_key = OpenAI_API
        GPT_API_URL = "https://api.openai.com/v1/chat/completions"
        all_reviews = "\n".join(df[Spalte].tolist())
        if st.button("Sentiment-Analyse starten"):

            @st.cache_data(ttl=600)
            def generate_proscons_list(text):
                word_blocks = text.split(' ')
                block_size = 1700
                blocks = [' '.join(word_blocks[i:i + block_size]) for i in range(0, len(word_blocks), block_size)]

                proscons = []

                for block in tqdm(blocks, desc="Processing blocks", unit="block"):
                    messages = [
                        {"role": "system", "content": "Du bist ein KI-Sprachmodell, das darauf trainiert ist, eine Liste der hÃ¤ufigsten StÃ¤rken und SchwÃ¤chen einer Tierarztpraxis auf der Grundlage von Google Bewertungen zu erstellen. Es ist dir nicht erlaubt, Ã¼ber die Liste der StÃ¤rken und SchwÃ¤chen hinaus einen Output zu generieren, also keine Zusammenfassung der Fragestellung oder des Ergebnisses."},
                        {"role": "user", "content": f"Erstelle auf der Grundlage der folgenden Google-Bewertungen eine Liste mit den hÃ¤ufigsten StÃ¤rken und SchwÃ¤chen der Tierarztpraxis: {block}"}
                    ]

                    completion = openai.ChatCompletion.create(
                        model="gpt-3.5-turbo",
                        messages=messages,
                        # You can change the max_tokens amount to increase or decrease the length of the results pros and cons list. If you increase it too much, you will exceed chatGPT's limits though.
                        max_tokens=250,
                        n=1,
                        stop=None,
                            # You can adjust how "creative" (i.e. true to the original reviewer's intent) chatGPT will be with it's summary be adjusting this temperature value. 0.7 is usually a safe amount
                        temperature=0.7
                    )

                    procon = completion.choices[0].message.content
                    proscons.append(procon)

                    # Gefundene StÃ¤rken und SchwÃ¤chen in einer Liste zusammenfassen 
                combined_proscons = "\n\n".join(proscons)
                return combined_proscons
            summary_proscons = generate_proscons_list(all_reviews)

            df_proscons = pd.DataFrame()
            list_proscons = []
            list_proscons.append(summary_proscons)
            df_proscons["pros_cons"] = list_proscons

            # Create Word document
            document = Document()
            document.add_heading("StÃ¤rken und SchwÃ¤chen Zusammenfassung", level=0)
            table = document.add_table(rows=len(df_proscons.index), cols=1)
            for i, row in df_proscons.iterrows():
                table.cell(i, 0).text = row["pros_cons"]
            document.add_page_break()

            # Download Word document
            with io.BytesIO() as output:
                document.save(output)
                if st.download_button(label='Download', data=output.getvalue(), file_name='Ergebnisse.docx', mime='application/vnd.openxmlformats-officedocument.wordprocessingml.document'):
                    pass

if input_method == Anleitung:
    st.title("Beschreibung & Kontakt")
    st.write("""Um das Tool optimal nutzen zu kÃ¶nnen, musst du dir bei Outscraper und OpenAI einen Account anlegen und einen API-Key erstellen. WICHTIG: Gib deinen Key nicht an Dritte weiter! 
    Die Links zur Anmeldung findest du hier:

    \n\nOutscraper: https://outscraper.com/refer?referrer=YXV0aDB8NjQwMWIzZGNiZmMzM2FhMmM5ODA4ZWFm

    \n\nOpenAI: https://chat.openai.com/auth/login


    \n\n\n\nSchritt 1: Web Scraping

    \n\nIm ersten Schritt, dem sogenannten Web Scraping, greift das Programm einleitend auf die Google-Maps Bewertungen der VetTrust zu und fasst diese innerhalb einer â€ž.csv (comma-seperated-values)â€œ-Datei zusammen, welche zentral Ã¼ber das Programm Excel geÃ¶ffnet werden kann. Um die relevanten Daten zu erhalten, muss zudem angegeben werden, von welchem Standort und ab welchem Zeitraum die Exporte benÃ¶tigt werden. DarÃ¼ber hinaus wird der zuvor erstellte API-Key benÃ¶tigt, um das Web Scraping endgÃ¼ltig durchzufÃ¼hren. Je nach Anzahl der Standorte sowie dem ausgewÃ¤hlten Zeitraum dauert diese Applikation wenige Sekunden bis einige Minuten. Das Ergebnis kann abschliessend heruntergeladen werden, um es entweder manuell zu betrachten oder im zweiten Schritt nÃ¤her zu analysieren.â€œ

    \n\n\n\nSchritt 2: Sentiment-Analyse

    \n\nZu Beginn des zweiten Schrittes wird die im vorherigen Schritt heruntergeladene .csv-Datei, die nun ausgewertet werden soll, wieder hochgeladen. Das Modell analysiert dabei die Texte auf positive und negative Aspekte, weshalb auch eigene DatensÃ¤tze mit gleichem Format verwendet werden kÃ¶nnen. Zu beachten ist, dass alle Textausschnitte in derselben Spalte vorliegen mÃ¼ssen, da diese sonst nicht fÃ¼r die Analyse erfasst werden kÃ¶nnen. Um die Analyse durchzufÃ¼hren, muss nach Upload der Daten zusÃ¤tzlich der Name der Spalte angegeben werden, die nachfolgend ausgewertet werden soll. Die auszuwertende Spalte, der in Schritt 1 exportierten Daten ist immer durch den Namen â€žReviewâ€œ gekennzeichnet, was jedoch bei eigenen DatensÃ¤tzen abweichen kann. Abschliessend muss auch hier wieder der passende API-Key angegeben werden. In AbhÃ¤ngigkeit der GrÃ¶sse des jeweiligen Datensatzes kann die Analyse einige Sekunden bis wenige Minuten dauern. Das endgÃ¼ltige Ergebnis kann dann als Word-Datei heruntergeladen werden, in der die StÃ¤rken und SchwÃ¤chen respektive positiven und negativen Aspekte der Bewertungen Ã¼bersichtlich aufgelistet sind.""")
    

    st.header("Kontaktformular")

    contact_form = """
    <form action="https://formsubmit.co/soeren.schlisske@web.de" method="POST">
        <input type="text" name="name" placeholder="Dein Name" required>
        <input type="email" name="email" placeholder="Deine Email-Adresse" required>
        <textarea name="message" placeholder="Deine Nachricht"></textarea>
        <button type="submit">Senden</button>
    </form>
    """

    st.markdown(contact_form, unsafe_allow_html=True)

    def local_css(file_name):
        with open(file_name) as f:
            st.markdown(f'<style>{f.read()}</style>', unsafe_allow_html=True)

    local_css("style/style.css")


   